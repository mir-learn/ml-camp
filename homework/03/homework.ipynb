{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17d988ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89e06230",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/course_lead_scoring.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13fad8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before:\n",
      "lead_source                 128\n",
      "industry                    134\n",
      "number_of_courses_viewed      0\n",
      "annual_income               181\n",
      "employment_status           100\n",
      "location                     63\n",
      "interaction_count             0\n",
      "lead_score                    0\n",
      "converted                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values before:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a96bf53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                  object\n",
       "industry                     object\n",
       "number_of_courses_viewed      int64\n",
       "annual_income               float64\n",
       "employment_status            object\n",
       "location                     object\n",
       "interaction_count             int64\n",
       "lead_score                  float64\n",
       "converted                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6c24245",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "cat_cols = list(df.select_dtypes(include=[\"object\", \"category\"]).columns)\n",
    "num_cols = list(df.select_dtypes(include=[np.number]).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38f10ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_cols:\n",
    "  df[c] = df[c].str.lower().str.replace(\" \", \"_\") if df[c].dtype == \"object\" else df[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caccf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cat_cols] = df[cat_cols].fillna(\"NA\")\n",
    "df[num_cols] = df[num_cols].fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f4a2c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent observation (mode) for 'industry': retail (count=203)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "industry\n",
       "retail           203\n",
       "finance          200\n",
       "other            198\n",
       "healthcare       187\n",
       "education        187\n",
       "technology       179\n",
       "manufacturing    174\n",
       "NA               134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Question 1: Most frequent observation (mode) for \"industry\"\n",
    "col = \"industry\"\n",
    "if col not in df.columns:\n",
    "    raise ValueError(f\"Column '{col}' not found. Available columns: {list(df.columns)}\")\n",
    "\n",
    "mode_value = df[col].value_counts(dropna=False).idxmax()\n",
    "mode_count = df[col].value_counts(dropna=False).max()\n",
    "\n",
    "print(f\"Most frequent observation (mode) for '{col}': {mode_value} (count={mode_count})\")\n",
    "\n",
    "# Optional: show top 10 frequencies\n",
    "df[col].value_counts(dropna=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58ea9427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected pair correlations:\n",
      "interaction_count ↔ lead_score: corr=0.009888 | abs=0.009888\n",
      "number_of_courses_viewed ↔ lead_score: corr=-0.004879 | abs=0.004879\n",
      "number_of_courses_viewed ↔ interaction_count: corr=-0.023565 | abs=0.023565\n",
      "annual_income ↔ interaction_count: corr=0.027036 | abs=0.027036\n",
      "\n",
      "► Pair with the largest absolute correlation (among the given options): ('annual_income', 'interaction_count') = 0.027036\n",
      "Shapes:\n",
      "  X_train: (877, 8) y_train: (877,)\n",
      "  X_val:   (292, 8) y_val:   (292,)\n",
      "  X_test:  (293, 8) y_test:  (293,)\n"
     ]
    }
   ],
   "source": [
    "# Qestion 2\n",
    "corr_matrix = df[num_cols].corr()\n",
    "corr_matrix\n",
    "\n",
    "pairs = [\n",
    "    (\"interaction_count\", \"lead_score\"),\n",
    "    (\"number_of_courses_viewed\", \"lead_score\"),\n",
    "    (\"number_of_courses_viewed\", \"interaction_count\"),\n",
    "    (\"annual_income\", \"interaction_count\"),\n",
    "]\n",
    "\n",
    "pair_corrs = {}\n",
    "missing_pairs = []\n",
    "\n",
    "for a, b in pairs:\n",
    "    if a in corr_matrix.index and b in corr_matrix.columns:\n",
    "        pair_corrs[(a, b)] = corr_matrix.loc[a, b]\n",
    "    else:\n",
    "        missing_pairs.append((a, b))\n",
    "\n",
    "print(\"Selected pair correlations:\")\n",
    "for (a, b), v in pair_corrs.items():\n",
    "    print(f\"{a} ↔ {b}: corr={v:.6f} | abs={abs(v):.6f}\")\n",
    "\n",
    "if missing_pairs:\n",
    "    print(\"\\nWarning: These pairs were not found in the dataframe (column missing):\")\n",
    "    for p in missing_pairs:\n",
    "        print(\" -\", p)\n",
    "\n",
    "if pair_corrs:\n",
    "    best_pair = max(pair_corrs.items(), key=lambda kv: abs(kv[1]))\n",
    "    print(f\"\\n► Pair with the largest absolute correlation (among the given options): {best_pair[0]} = {best_pair[1]:.6f}\")\n",
    "else:\n",
    "    print(\"\\nNo valid pairs found. Check column names in the dataset.\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TARGET_COL = \"converted\"\n",
    "if TARGET_COL not in df.columns:\n",
    "    raise ValueError(f\"Target column '{TARGET_COL}' not found. Available columns: {list(df.columns)}\")\n",
    "\n",
    "# Try to convert target to numeric (handles 'yes'/'no' or '0'/'1')\n",
    "y_raw = df[TARGET_COL]\n",
    "if not np.issubdtype(y_raw.dtype, np.number):\n",
    "    # Attempt numeric coercion first\n",
    "    y_num = pd.to_numeric(y_raw, errors=\"coerce\")\n",
    "    if y_num.isna().any():\n",
    "        # Map common string labels\n",
    "        map_dict = {\"yes\": 1, \"no\": 0, \"y\": 1, \"n\": 0, \"true\": 1, \"false\": 0, \"1\": 1, \"0\": 0}\n",
    "        y_num = y_raw.astype(str).str.lower().map(map_dict)\n",
    "    y = y_num.fillna(0).astype(int).values\n",
    "else:\n",
    "    y = y_raw.astype(int).values\n",
    "\n",
    "# Feature matrix without target\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "\n",
    "# First split: train (60%) and temp (40%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: temp into val (20%) and test (20%) -> each is half of temp (i.e., 0.2 of total)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  X_train:\", X_train.shape, \"y_train:\", y_train.shape)\n",
    "print(\"  X_val:  \", X_val.shape,   \"y_val:  \", y_val.shape)\n",
    "print(\"  X_test: \", X_test.shape,  \"y_test: \", y_test.shape)\n",
    "\n",
    "# Quick sanity check that target is not inside features\n",
    "assert TARGET_COL not in X_train.columns\n",
    "assert TARGET_COL not in X_val.columns\n",
    "assert TARGET_COL not in X_test.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4116370e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual information (rounded to 2 decimals):\n",
      "  industry: 0.02\n",
      "  location: 0.0\n",
      "  lead_source: 0.03\n",
      "  employment_status: 0.02\n",
      "\n",
      "► Variable with the largest MI (among the given options): lead_source (score=0.03)\n"
     ]
    }
   ],
   "source": [
    "# Qestion 3\n",
    "\n",
    "# Identify categorical columns in the TRAIN split only\n",
    "cat_cols_train = list(X_train.select_dtypes(include=[\"object\", \"category\"]).columns)\n",
    "\n",
    "# Helper to compute MI safely\n",
    "def mi_with_y(y, series):\n",
    "    return mutual_info_score(y, series)\n",
    "\n",
    "candidates = [\"industry\", \"location\", \"lead_source\", \"employment_status\"]\n",
    "\n",
    "mi_results = {}\n",
    "missing = []\n",
    "\n",
    "for col in candidates:\n",
    "    if col in X_train.columns and col in cat_cols_train:\n",
    "        score = mi_with_y(y_train, X_train[col])\n",
    "        mi_results[col] = round(score, 2)\n",
    "    elif col in X_train.columns:\n",
    "        # Column exists but isn't categorical per dtype -> still attempt MI on raw values\n",
    "        score = mi_with_y(y_train, X_train[col].astype(str))\n",
    "        mi_results[col] = round(score, 2)\n",
    "    else:\n",
    "        missing.append(col)\n",
    "\n",
    "print(\"Mutual information (rounded to 2 decimals):\")\n",
    "for k, v in mi_results.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "\n",
    "if missing:\n",
    "    print(\"\\nWarning: Missing columns in training data:\", missing)\n",
    "\n",
    "if mi_results:\n",
    "    best = max(mi_results.items(), key=lambda kv: kv[1])\n",
    "    print(f\"\\n► Variable with the largest MI (among the given options): {best[0]} (score={best[1]})\")\n",
    "else:\n",
    "    print(\"\\nNo candidate variables found in training data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07ad7912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7432\n",
      "Validation accuracy (rounded to 2 decimals): 0.74\n"
     ]
    }
   ],
   "source": [
    "# Qestion 4\n",
    "# Identify categorical and numerical columns from TRAIN data\n",
    "cat_cols_train = list(X_train.select_dtypes(include=[\"object\", \"category\"]).columns)\n",
    "num_cols_train = list(X_train.select_dtypes(include=[np.number, \"bool\"]).columns)\n",
    "\n",
    "# Preprocessor: OneHot for categoricals, pass-through for numericals\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols_train),\n",
    "        (\"num\", \"passthrough\", num_cols_train),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Build the pipeline\n",
    "logreg_clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"model\", LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit on TRAIN\n",
    "logreg_clf.fit(X_train, y_train)\n",
    "\n",
    "# Validate on VAL\n",
    "y_val_pred = logreg_clf.predict(X_val)\n",
    "val_acc = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "print(f\"Validation accuracy (rounded to 2 decimals): {round(val_acc, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84de2437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline validation accuracy (all features): 0.7431506849315068\n",
      "\n",
      "Per-feature removal results (sorted by absolute difference):\n",
      "          feature  val_acc_without  difference (baseline - without)  abs_difference\n",
      "         industry         0.743151                         0.000000        0.000000\n",
      "       lead_score         0.743151                         0.000000        0.000000\n",
      "employment_status         0.746575                        -0.003425        0.003425\n",
      "\n",
      "► Least impact (smallest |difference|): 'industry' (difference=0.0)\n"
     ]
    }
   ],
   "source": [
    "# Question 5\n",
    "\n",
    "# Recreate the baseline pipeline (same as Q4)\n",
    "cat_cols_train = list(X_train.select_dtypes(include=[\"object\", \"category\"]).columns)\n",
    "num_cols_train = list(X_train.select_dtypes(include=[np.number, \"bool\"]).columns)\n",
    "\n",
    "baseline_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols_train),\n",
    "        (\"num\", \"passthrough\", num_cols_train),\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_clf = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", baseline_preprocessor),\n",
    "        (\"model\", LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_clf.fit(X_train, y_train)\n",
    "baseline_pred = baseline_clf.predict(X_val)\n",
    "baseline_acc = accuracy_score(y_val, baseline_pred)\n",
    "print(\"Baseline validation accuracy (all features):\", baseline_acc)\n",
    "\n",
    "# Helper: train & eval with a subset of columns\n",
    "def eval_without(feature_to_drop: str):\n",
    "    if feature_to_drop not in X_train.columns:\n",
    "        return np.nan  # feature not present\n",
    "\n",
    "    cols_after_drop = [c for c in X_train.columns if c != feature_to_drop]\n",
    "\n",
    "    Xtr = X_train[cols_after_drop]\n",
    "    Xv  = X_val[cols_after_drop]\n",
    "\n",
    "    cat_cols = list(Xtr.select_dtypes(include=[\"object\", \"category\"]).columns)\n",
    "    num_cols = list(Xtr.select_dtypes(include=[np.number, \"bool\"]).columns)\n",
    "\n",
    "    pre = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
    "            (\"num\", \"passthrough\", num_cols),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocess\", pre),\n",
    "            (\"model\", LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    clf.fit(Xtr, y_train)\n",
    "    yv_pred = clf.predict(Xv)\n",
    "    acc = accuracy_score(y_val, yv_pred)\n",
    "    return acc\n",
    "\n",
    "candidates = [\"industry\", \"employment_status\", \"lead_score\"]\n",
    "\n",
    "rows = []\n",
    "for f in candidates:\n",
    "    acc_wo = eval_without(f)\n",
    "    diff = baseline_acc - acc_wo if pd.notnull(acc_wo) else np.nan\n",
    "    rows.append(\n",
    "        {\n",
    "            \"feature\": f,\n",
    "            \"val_acc_without\": acc_wo,\n",
    "            \"difference (baseline - without)\": diff,\n",
    "            \"abs_difference\": abs(diff) if pd.notnull(diff) else np.nan,\n",
    "        }\n",
    "    )\n",
    "\n",
    "results_df = pd.DataFrame(rows).sort_values(\"abs_difference\", ascending=True)\n",
    "print(\"\\nPer-feature removal results (sorted by absolute difference):\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "if results_df[\"abs_difference\"].notna().any():\n",
    "    least_impact_row = results_df.iloc[0]\n",
    "    print(\n",
    "        f\"\\n► Least impact (smallest |difference|): '{least_impact_row['feature']}' \"\n",
    "        f\"(difference={least_impact_row['difference (baseline - without)']})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50fa4fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     C  val_acc_rounded_3\n",
      "  0.01              0.743\n",
      "  0.10              0.743\n",
      "  1.00              0.743\n",
      " 10.00              0.743\n",
      "100.00              0.743\n",
      "\n",
      "► Best C (chosen by max rounded accuracy, tie -> smallest C): 0.01\n"
     ]
    }
   ],
   "source": [
    "# Quetion 6\n",
    "\n",
    "Cs_q6 = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Column sets from TRAIN (same logic as Q4; we don't modify earlier variables)\n",
    "cat_cols_q6 = list(X_train.select_dtypes(include=[\"object\", \"category\"]).columns)\n",
    "num_cols_q6 = list(X_train.select_dtypes(include=[np.number, \"bool\"]).columns)\n",
    "\n",
    "records = []\n",
    "\n",
    "for C in Cs_q6:\n",
    "    pre_q6 = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols_q6),\n",
    "            (\"num\", \"passthrough\", num_cols_q6),\n",
    "        ]\n",
    "    )\n",
    "    clf_q6 = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocess\", pre_q6),\n",
    "            (\"model\", LogisticRegression(solver=\"liblinear\", C=C, max_iter=1000, random_state=42)),\n",
    "        ]\n",
    "    )\n",
    "    clf_q6.fit(X_train, y_train)\n",
    "    y_val_pred_q6 = clf_q6.predict(X_val)\n",
    "    acc_q6 = accuracy_score(y_val, y_val_pred_q6)\n",
    "    acc_q6_round = round(acc_q6, 3)\n",
    "    records.append({\"C\": C, \"val_acc\": acc_q6, \"val_acc_rounded_3\": acc_q6_round})\n",
    "\n",
    "results_q6 = pd.DataFrame(records).sort_values(\"C\")\n",
    "print(results_q6[[\"C\", \"val_acc_rounded_3\"]].to_string(index=False))\n",
    "\n",
    "# Select best by **rounded** accuracy; tie -> smallest C\n",
    "max_rounded = results_q6[\"val_acc_rounded_3\"].max()\n",
    "best_candidates = results_q6[results_q6[\"val_acc_rounded_3\"] == max_rounded]\n",
    "best_C_final = float(best_candidates[\"C\"].min())\n",
    "\n",
    "print(f\"\\n► Best C (chosen by max rounded accuracy, tie -> smallest C): {best_C_final}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757dc6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
